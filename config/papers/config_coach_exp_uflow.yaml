[defaults]
#config/papers/config_coach_exp_uflow.yaml
run-tag: uflow
#run-tag: default
run-start: new

#(state-of-the-art): 2021_04_19_v25_uflow (requires finetuning for 832x256)

model-load-modules: {
   '2021_04_19_v25_uflow': ['module_disp', 'module_flow'],
}

#model-load-modules: {
#   '2021_04_15_v112_oflow': ['module_disp'],
#   '2020_10_26_uflow': ['module_flow'],
#  }

wandb-log-metrics: True
wandb-log-state: True
wandb-log-model: False

# those three things might be quite important: resolution, architecture, normalize_features
#arch-res-width: 640
#arch-res-height: 640
arch-context-out-channels: 32
arch-context-dropout: True
arch-context-densenet: True
arch-flow-res: True
arch-flow-encoder-type: pwcnet
arch-flow-out-channels: 2
arch-flow-dropout: True
arch-modules-features-convs-per-lvl: 3 # 2 or 3
arch-cost-volume-normalize-features: True
#arch-modules-features-channels: [3, 32, 64, 96, 128, 192, 256]
arch-modules-features-channels: [3, 32, 32, 32, 32, 32]
# actually smsf: [3, 32, 64, 96, 128, 192, 256]
# default / uflow: [3, 32, 32, 32, 32, 32]
# sflow-mono-sf [3, 16, 32, 64, 96, 128, 196]

arch-disp-encoder: resnet #resnet | unet | none
arch-disp-separate: True
arch-disp-out-channels: 1
arch-disp-dropout: False
arch-disp-res: False
arch-disp-activation-before-refinement: False
arch-disp-activation: identity # sigmoid | relu
arch-disp-rel-inside-model: False

loss-lvl-weights: [4., 0., 2., 1., 1.] # [4., 4., 2., 1., 1., 1.]

# in orig uflow: disp-photo and flow-photo is balanced
loss-disp-photo-lambda: 2.0 # 2.0

loss-disp-smooth-lambda: 2. #0.1 / 832 * 2 * 2 = 0.00012 * 4 = 0.00048
# * 2 cause of disp1/disp2 , * 2 cause of grad_x, grad_y
loss-disp-smooth-order: 2
loss-disp-smooth-edgeweight: 150 # 150 -> 15

loss-disp-flow-cons3d-lambda: 0. # 0.4 # 0.2 * 2 = 0.4 (2. * forward - backward)
loss-disp-flow-cons3d-type: smsf # smsf or chamfer

loss-disp-se3-cons3d-lambda: 0. # 0.4 # 0.2 * 2 = 0.4 (2. * forward - backward)
loss-disp-se3-cons3d-type: smsf # smsf or chamfer
loss-disp-se3-cons3d-fwdbwd: True

loss-flow-photo-lambda: 2. # 2. # 2.0
loss-photo-type: ssim # census or ssim


loss-flow-smooth-lambda: 2. # 800. # 800 # 800 # 200 * 2 * 2= 800
loss-flow-smooth-order: 2
loss-flow-smooth-edgeweight: 150 # 150 -> 15 | 10 / 2 (because img_gradient have stride=2)

train-dataset-name: kitti-multiview
train-seed: 34
train-batch-size: 1
train-accumulate-grad-batches: 1
train-num-epochs-max: 200
train-dataset-max-num-imgs: 2

# Optimization options
optimization: adam
lr:           0.0001 # 0.0002 -> 0.00002
# in uflow it start with 0.0001 and after m steps it is decayed from 1e-4 to 1e-8 in m/5 steps
lr-scheduler-steps: [40, 80, 120, 160]

# momentum is not passed through for adam.
momentum:     0.0
weight-decay: 0.0

